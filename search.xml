<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[聚类算法之meanShift]]></title>
    <url>%2F2019%2F05%2F14%2F%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BmeanShift%2F</url>
    <content type="text"><![CDATA[前言在开始Meanshift之前需要先弄懂K-means，因为K-means的缺点（需要事先设置族的数量K，和起始族中心），可是大多时候，人工并不能完美的设置K和起始中心，就会导致，本来可以聚成5类的，结果只聚成4类等一系列问题。而MeanShift（均值漂移）解决了这些问题.MeanShift算是对K-means的一种改进。首先不需要事先输入K，而是根据族心漂移，自动聚集出K类；另外，基于可以漂移自动聚类，那么起始族心也不需要提前输入，可以拿数据中所有的元素作为起始族心（只是会增加过量计算，这篇中我会做数据粗粒化处理，来减少过量计算） 算法核心思想对于所有起始族心，计算其规定球内所有元素的均值作为下一个族心，当前族心到新的族心的向量叫做偏移向量。新的均值族心计算函数： ​ 上式默认为球内每个元素权重一样。那么从t时刻到t+1时刻均值中心的偏移向量为： 而在MeanShift聚类过程中为了加快收敛，引入了核函数。相当于在给当前球内所有点加上一个相对球心的高斯权重（也可以加入其他和函数），偏移向量变成如下： 至于 为什么加入高斯核函数后能够实现加速收敛，推导过程：https://www.cnblogs.com/liqizhou/archive/2012/05/12/2497220.html，可以参考这篇文章，详细讲解了推导过程。 通过加入核函数的偏移向量，可以计算出新的球心： g(x)为高斯函数：h表述球半径（带宽） 高斯函数曲线： 从高斯曲线可以看出：离当前球心越近的点的权重越大。 算法流程1、以所有点作为起始点（可以根据实际情况稀释起始点）； 2、找出离center距离在bandwidth之内的所有点，记做集合M，认为这些点属于簇c。同时，统计属于蔟c的点的个数，这个参数将用于最后步骤的分类 3、然后计算当前center内以bandwidth为半径所有点的新的newcenter。 4、偏移向量为shift = newcenter - center。 移动距离是||shift||。 5、重复步骤2、3、4，直到shift的大小很小（就是迭代到收敛），记住此时的newcenter。 6、如果收敛时当前簇c的center与其它已经存在的簇c2中心的距离小于阈值，那么c2和c只能留下一个，留下以bandwidth为半径，球内点多的center。 6、重复1、2、3、4、5直到所有的点都被标记访问。 7、分类：根据每个蔟，对每个点的计算距离，取距离最近的那个簇心，作为当前点集的所属蔟。 最后效果图： 完整代码传送门（github）：https://github.com/RoryXiang/MCL_dairy/blob/master/Clustering/MeanShift.py]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>聚类</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AntAlgorithm(蚁群算法)]]></title>
    <url>%2F2019%2F05%2F06%2F%E8%9A%82%E8%9A%81%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[​ 在我完全搞明白蚂蚁算法之前，我也在网上找了好多资料，每个都看完，都有一个特点，就是，不管谁的blog或者论文，都是会放上三个数学公式，或者再加上一段对应数学公式的代码。对于非专科生来说非常头疼。这里我按照我的理解通俗的分享一下。 #核心思路 ​ 本算法的原理是模仿蚂蚁在自然界的行为，但是又有点不同。蚂蚁在行径的路途中会释放激素，以便于自己活着其他蚂蚁找到走过的路径，激素是有挥发性的，时间越久激素的浓度就会越低，被识别的概率越低。（这也是算法的硬核所在）。所以在算法中，每个蚂蚁没跑完一次路径所携带的信息素总量是一定的，路径越长，那么单位路径上的信息素就越少，被重复选择个概率就越小，而被淘汰。另外信息素在路上可以累加的，但是会随意间挥发，所有的这些影响因素慢慢的叠加，最终就可以选择出最短路径。 #数学模型 ​ 一）、第一个数学模型函数，下一个城市选择概率函数： 这个数学公式的意思是，当前在地 i 个城市，选择下一个城市 j 的概率（j代表所有城市中非 i 的城市）。 ##分子： 前半部分： 表示城市 i，j 之间的信息因素（所有蚂蚁在城市 i，j 之间留下的信息素总和，即信息浓度） 后半部分： 表示城市 i，j 之间的距离距离因素（默认为距离的倒数） ##分母： 表示当前城市 i 到所有可以到达的城市的 信息因素与距离因素乘机的加和。 这一步我们知道了从当前城市到每一个城市的概率，那么接下来就是按照概率来选择下一个城市。这里我们采用轮盘算法（也可以用numpy.choise(target, size, p)来选择下一个城市） 选择下一个城市的代码块： 123456789101112131415161718192021222324252627282930313233343536373839def __choice_next_city(self): # 初始化转移概率矩阵（从当前城市到每一个城市的概率） cities_prob = np.zeros(shape=(city_num,)) # cities_prob = list(cities_prob) # 将numpy矩阵转换成list total_prob = 0.0 # 用概率函数计算概率矩阵(联想选路概率函数) for next_city in range(city_num): if self.callable_city[next_city]: try: # cities_prob[next_city] = np.power( # pheromone_graph[self.current_city][next_city], ALPHA) * np.power(1.0 / distance_graph[self.current_city][next_city], BATA) cities_prob[next_city] = pow( pheromone_graph[self.current_city][next_city], ALPHA) * pow(1.0 / distance_graph[self.current_city][next_city], BATA) total_prob += cities_prob[next_city] except ZeroDivisionError as e: print( f"Ant ID: &#123;self.ID&#125;, current city: &#123;self.current_city&#125;, target city: &#123;next_city&#125;") sys.exit(1) # 选择下一个城市 （貌似用轮盘算法比用numpy快） # next_city = np.random.choice(np.arange(city_num), size=1, p=cities_prob / float(total_prob)) # 轮盘算法 next_city = None if total_prob &gt; 0: temp_prob = random.uniform(0.0, total_prob) for i in range(city_num): if self.callable_city[i]: temp_prob -= cities_prob[i] if temp_prob &lt; 0.0: next_city = i break # 第一个循环的时候，只能随机选择 if not next_city: next_city = random.randint(0, city_num - 1) while not self.callable_city[next_city]: next_city = random.randint(0, city_num - 1) return next_city ​ 二）、从城市的选择概率函数可以看到，有两个影响因素，一个是距离因素，这个没两个城市之间是固定的。另外一个就是信息浓度，τ(i,j).信息浓度会在每只蚂蚁经过之后增加，另外，信息也会随着时间会发，所以信息浓度会有一个更新函数： 第一个函数表示 i， j两个城市之间的信息浓度从t时刻到t+1时刻后 ρ 表示信息素的挥发速度。∇τ(i,j)表示所有的蚂蚁在 i，j 之间留下的信息素之和。δτ(ij)表示每只蚂蚁在 i，j 两个城市之间留下的信息素。 信息浓度更新代码： 1234567891011121314151617def __uodate_pheromone_graph(self): """更新信息素""" # 初始化蚂蚁本轮释放的信息矩阵（每只蚂蚁的信息素都需要加进来）: 相当于计算 △Tij temp_pheromone = np.zeros((city_num, city_num)) # temp_pheromone = list(temp_pheromone) # 将numpy矩阵转换成list for ant in self.ants: # 将所有蚂蚁在路径上留下的信息素叠加 for i in range(1, city_num): start, end = ant.path[i - 1], ant.path[i] # 这里用到蚂蚁信息素释放模型函数 temp_pheromone[start][end] += Q / ant.total_distance temp_pheromone[end][start] = temp_pheromone[start][end] # 更新信息素矩阵 (用到信息素浓度更新函数) for i in range(city_num): for j in range(city_num): pheromone_graph[i][j] = pheromone_graph[i][j] * \ RHO + temp_pheromone[i][j] 三）、在第二步信息浓度更新函数的第二个函数中，还有一个未解决的变量δτ(ij)。所有这里涉及到第三个函数模型：蚂蚁信息素释放模型： Q是常量参数（一般设置为1、10、100等），表示每只蚂蚁一次循环释放的信息总量；L表示每只蚂蚁当次完整路线的总距离。 因为Q是定值，所以当蚂蚁的路线总路程L越短的时候释放的信息素δτ(ij)就会越大，对于信息素浓度来说，当t+1时刻，就会有更大的∇τ(i,j)，和更大的信息浓度τ(i,j)，所以在t+1时刻，被选择的概率就会更大，以这样一次一次叠加，最终选择出来最短的路径。 整个算法的核心流程初始化蚂蚁种群。开始跑第一个循环（第一个循环的时候，路径上没有历史信息素，所以第一轮的时候每只蚂蚁都是随机选择下一个城市），第一次循环完成后，需要计算每只蚂蚁的总路程、计算每只蚂蚁的信息释放量，更新所有城市之间的信息浓度；接着跑第二轮，第二轮往后，每次选择下一个城市的概率就会产生差异，然后重复第一轮所需要做的所有更新。 完整代码传送门（github）：https://github.com/RoryXiang/MCL_dairy/blob/master/AG/AGTSP.py 最后附上一篇关于蚂蚁算法中各个参数的影响的论文： 链接:https://pan.baidu.com/s/1UWv0Q3oboc22R8B5VRvmSw 密码:lnp8 下一篇准备花点时间看看所有的聚类算法然后分享一下。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GeneticAlgorithm(遗传算法)]]></title>
    <url>%2F2019%2F04%2F12%2FGeneticAlgorithm%2F</url>
    <content type="text"><![CDATA[​ 第一篇写遗传算法，一是因为我接触第一个算法，另外就是它的用途很广，很多方向都能用到。一般都用在解决：函数最值问题、TSP（旅行商问题）、背包问题等等。 ​ 遗传算法完全的模拟生物的遗传过程，所以算法的核心也是可以用生物的遗传过程来理解：遗传和变异🧬，适者生存（选择优胜者）。算法的难点也是在实际业务或者使用中，如何将实际问题转化成数学模型中的模型。 开始第一个demo（解决TSP问题，求最短路径）：​ 以20个城市举例，找出者20个城市的最短路径。 ​ 遗传算法在解决这个问题的时候，核心是：遗传、变异函数，这里我们采用的是一部分基因来自父亲，一部分来自母亲，例如，father = [1, 4, 5, 2, 3], motner = [2, 4, 3, 5, 1] 则孩子可能为 [1, 4, 3, 2, 5],前半部分基因来自父亲，后半部分来自母亲，顺序都需要保持父母的。变异呢，则是，随机更换任意两个位置的城市为[1, 4, 1,5, 2, 3], 5, 3换位置。 交叉函数（生孩子的过程）12345678910111213141516171819202122232425def crossover(self, father, people): """交叉配对函数。原理是，选择父亲的一部分城市排序，然后剩余的城市排序按照母亲的排序方式组合成孩子路线方案 Arguments: father [city1,city2..] -- 所有的城市排序 people [[city1,city2..],[city4,city10..]] -- 所有的路线方案 Returns: [city1,city2..] -- 生成的孩子路线方案或者父亲路线 """ if np.random.rand() &lt; self.cross_rate: # 从people中选择另一个parent mother_index = np.random.randint(0, self.people_size, size=1) # 选择交叉的DNA下标 cross_points = np.random.randint(0, 2, self.DNA_size, dtype=np.bool) # 选择father部分的城市（排序方式为father已有的排序） father_city = father[cross_points] # 选择father没选上的城市（排序方式为mother以后的排序） mother_city = people[mother_index, np.isin( people[mother_index].ravel(), father_city, invert=True)] child = np.concatenate((father_city, mother_city)) # time.sleep(10) # father[:] = np.concatenate((father_city, mother_city)) # return father return child return father 变异函数1234567891011121314def mutate(self, child): """变异函数。每个城市都有几率产生变异。变异：随机与路线上的另外一个城市交换位置 Arguments: child [int] -- 路线方案 Returns: child [int] -- 路线方案 """ for point_index in range(self.DNA_size): if np.random.rand() &lt; self.mutation_rate: swap_point_index = np.random.randint(0, self.DNA_size) swap_A, swap_B = child[point_index], child[swap_point_index] child[point_index], child[swap_point_index] = swap_B, swap_A return child 完成了遗传变异的过程，生物种群就会增多，接下来就是适者生存，择优的过程。但是在做选择的时候，需要有一个选择标准来判断那个个体更适合。在解决TSP，那么每个个体的路线长短则作为判断依据（路线短的优胜）。这里就需要一个计算适应性的函数。 适应性计算函数12345678910111213141516171819def get_fitness(self, xs_values, ys_values): """计算每条路线的距离distance，并且以距离的倒数为e的指数的值作为fitness Arguments: xs_values [[float]]-- 所有路线的x坐标列表 ys_values [[float]]-- 所有路线的y坐标列表 Returns: fitness [float] -- 每条路线的适应性 total_distance [float] -- 每条路线的距离 """ total_distance = np.empty((xs_values.shape[0], ), dtype=np.float64) for index, (x_values, y_values) in enumerate(zip(xs_values, ys_values)): total_distance[index] = np.sum( np.sqrt(np.square(np.diff(x_values)) + np.square(np.diff(y_values)))) fitness = np.exp(self.DNA_size * 2 / total_distance) # 这里为什么要乘以self.DNA_size * 2，因为基数太小，fitness之间差距太小，在做select的时候就会每个概率几乎相等了，收敛太慢，放大后概率差就更凸显 # fitness1 = np.exp(1 / total_distance) # print("???????", fitness, fitness1) return fitness, total_distance 选择函数这个选择函数的思想是，从种群中选择新的种群，每个个体都可以被重复选择，但是适应性高的个体被重复选择的概率高，适应性低的个体，可能一次都选不上，replace=True表示可被重复选择，p=fitness / fitness.sum()表示每个个体的选择概率 123456def select(self, fitness): """选择函数 """ index = np.random.choice(np.arange( self.people_size), size=self.people_size, replace=True, p=fitness / fitness.sum()) return self.people[index] 进化函数当前种群的一次进化，先根据适应性选择新的种群，然后在对每个个体进行交叉遗传并对遗传的新个体产生变异 12345678910111213def evolve(self, fitness): """进化函数（一次进化） Arguments: fitness &#123;[type]&#125; -- [description] """ people = self.select(fitness) people_copy = people.copy() for father in people: child = self.crossover(father, people_copy) child = self.mutate(child) # father[:] = child father = child self.people = people 整个求解的流程首先初始化一个生物种群： 12ga = GA(DNA_size=CITY_NUM, cross_rate=CROSS_RATE, mutation_rate=MUTATION_RATE, people_size=POP_SIZE) # 初始化种群 初始化20个城市: 1env = TSP(city_num=CITY_NUM) # 初始化20是个城市 然后根据定义的遗传代数来逐代进化 123456789101112for generation in range(N_GENERATION): # 计算出所有个体的坐标 x_values, y_values = ga.translate_DNA(ga.people, env.city_position) # 计算出所有个体的适应性+路程 fitness, total_distance = ga.get_fitness(x_values, y_values) # 遗传演变 ga.evolve(fitness) # 找出适应性最高的个体 best_idx = np.argmax(fitness) print('Gen:', generation, '| best fit: %.2f' % fitness[best_idx],) env.ploting(x_values[best_idx], y_values[best_idx], total_distance[best_idx]) 完整代码传送门： https://github.com/RoryXiang/MCL_dairy/blob/master/GeneticAlgorithm/shortest_path.py 下一篇是蚂蚁算法来解决TSP]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
</search>
